# Data Ingestion and Processing Pipeline


# Introduction
This project implements a data ingestion and processing pipeline to collect, store and process time-series data. The pipeline consists of a publisher, a message queue (Pub/Sub), a consumer, a data warehouse (BigQuery) and a data extractor. The pipeline is designed to be scalable, efficient and easy to maintain.

# Deployment
The solution can be deployed using Docker and Docker-compose or any other tool. The pipeline components can be deployed as individual containers for easy scaling and maintenance.
