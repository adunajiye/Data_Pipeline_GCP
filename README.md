# Data Ingestion and Processing Pipeline


# Introduction
This project implements a data ingestion and processing pipeline to collect, store and process time-series data. The pipeline consists of a publisher, a message queue (Pub/Sub), a consumer, a data warehouse (BigQuery) and a data extractor. The pipeline is designed to be scalable, efficient and easy to maintain.

# Deployment
The solution can be deployed using Docker and Docker-compose or any other tool. The pipeline components can be deployed as individual containers for easy scaling and maintenance.

# Prerequisites
Before you start using the pipeline, make sure you have the following software installed:

<li>Python 3.x</li>
<li>The google-cloud-pubsub Python packages installed in your environment</li>
<li>Docker (optional)</li>

# Installation

